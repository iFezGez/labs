{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Vesta Lab \u2013 Technical Infrastructure","text":"<p>Welcome to the documentation of Vesta Lab, an internal R&amp;D environment built by Ignacio Fernandez, CEO of Vesta Security LATAM S.A.</p> <p>This repository demonstrates the design, implementation, and management of a full-stack virtualization and automation lab, including:</p> <ul> <li>Virtualization (Proxmox)</li> <li>Storage (TrueNAS)</li> <li>Containers (Docker &amp; Portainer)</li> <li>VPN &amp; Network Security (WireGuard, Tailscale, MikroTik)</li> <li>Monitoring (Grafana, Prometheus, Uptime Kuma)</li> <li>Backup (PBS, TrueNAS, cloud)</li> <li>Internal Services (GitLab, Vaultwarden, AdGuard)</li> <li>ERP Modules (Odoo, Invoice Ninja)</li> </ul> <p>Explore the individual sections via the left navigation bar. Each module includes:</p> <ul> <li>Step-by-step installation</li> <li>Architecture diagrams</li> <li>Real screenshots</li> <li>Exported configs &amp; scripts</li> <li>Docker Compose &amp; cloud-init templates</li> </ul> <p>Created &amp; maintained by: Ignacio Fernandez Website: https://vestasec.com</p>"},{"location":"architecture/","title":"Lab Network Topology \u2013 Vesta Lab","text":"<p>This document describes the full IP topology, VLAN segmentation, gateway setup, and service role of each machine in the Vesta technical laboratory.</p>"},{"location":"architecture/#network-layout","title":"\ufe0f Network Layout","text":"Node Hostname IP VLAN Subnet Role Proxmox VE 1 proxmox-ve1 10.10.0.2 10 10.10.0.0/24 Main Proxmox node Proxmox VE 2 proxmox-ve2 10.10.0.3 10 10.10.0.0/24 Second Proxmox node Docker Node 1 docker-ve1 10.20.0.2 20 10.20.0.0/24 Core services node (ve1) Docker Node 2 docker-ve2 10.20.0.3 20 10.20.0.0/24 Auxiliary services node PBS Server pbs 10.30.0.2 30 10.30.0.0/24 Backup server TrueNAS truenas 10.30.0.3 30 10.30.0.0/24 NFS storage and datasets Router mikrotik 10.0.0.102 mgmt 10.0.0.0/24 VLAN router + DNS/DHCP"},{"location":"architecture/#gateway-mapping","title":"Gateway Mapping","text":"<p>Each VLAN has its own gateway handled by MikroTik:</p> <ul> <li>VLAN 10 (mgmt): <code>10.10.0.1</code></li> <li>VLAN 20 (services): <code>10.20.0.1</code></li> <li>VLAN 30 (storage): <code>10.30.0.1</code></li> </ul>"},{"location":"architecture/#mikrotik-routing-and-vlans","title":"MikroTik Routing and VLANs","text":"<p>Full MikroTik configuration is stored in <code>network/mikrotik/config_files/full_config.rsc</code>. It handles: - Trunk ports - Bridge interfaces - Static DHCP leases - DNS and routing for each VLAN</p>"},{"location":"architecture/#vesta-lab-benchmark-results","title":"Vesta Lab \u2013 Benchmark Results","text":"<p>These tests were performed to verify the performance and reliability of physical hardware and virtualized environments in the lab.</p>"},{"location":"architecture/#disk-io-test-with-fio","title":"Disk I/O Test with <code>fio</code>","text":"<pre><code>apt install fio -y\nfio --name=randwrite --ioengine=libaio --rw=randwrite \\\n  --bs=4k --direct=1 --size=1G --numjobs=4 --runtime=60 --group_reporting\n</code></pre> <p>ve1 (ZFS SSD 500 GB): - IOPS: ~22,000 - BW: ~90\u2013120 MB/s</p>"},{"location":"architecture/#disk-io-with-bonnie","title":"Disk I/O with <code>bonnie++</code>","text":"<pre><code>apt install bonnie++ -y\nbonnie++ -d /tmp -s 2048 -r 1024 -u root\n</code></pre> <p>ve1: - Seq Write: ~250 MB/s - Seq Read: ~420 MB/s</p>"},{"location":"architecture/#network-throughput-with-iperf3","title":"Network Throughput with <code>iperf3</code>","text":"<p>Server: <pre><code>iperf3 -s\n</code></pre></p> <p>Client: <pre><code>iperf3 -c 10.10.0.2\n</code></pre></p> <p>ve2 \u2192 ve1 (VLAN 10): - Bandwidth: ~950 Mbits/sec (virtio-net)</p>"},{"location":"architecture/#cpu-stress-test-with-stress-ng","title":"CPU Stress Test with <code>stress-ng</code>","text":"<pre><code>apt install stress-ng -y\nstress-ng --cpu 2 --timeout 60s --metrics-brief\n</code></pre> <p>ve1: - Load remained under threshold - Temps stable with passive cooling</p>"},{"location":"architecture/#summary","title":"Summary","text":"Test Result (ve1) Disk IOPS ~22,000 Disk Read ~420 MB/s Network BW ~950 Mbits/sec CPU Stable Yes (2 vCPU under load) <p>These metrics confirm the lab's capability to run production-like workloads for testing, monitoring, and containerization.</p>"},{"location":"backups/","title":"TrueNAS + PBS + NFS Integration","text":"<p>This document explains how the Vesta Lab connects its storage and backup systems using TrueNAS SCALE and Proxmox Backup Server.</p>"},{"location":"backups/#infrastructure-summary","title":"Infrastructure Summary","text":"Component Hostname IP VLAN Role TrueNAS truenas 10.30.0.3 30 NFS storage provider PBS pbs 10.30.0.2 30 Backup server (Proxmox) Network vmbr0.30 10.30.0.0/24 30 Dedicated storage VLAN"},{"location":"backups/#1-dataset-creation-in-truenas","title":"1. Dataset Creation in TrueNAS","text":"<ul> <li>Pool: <code>lab-pool</code></li> <li>Dataset: <code>lab-backups</code></li> <li>Share Type: NFS</li> <li>Mapall User/Group: <code>root</code></li> <li>Permissions: POSIX, recursive RW</li> </ul>"},{"location":"backups/#nfs-share-settings","title":"NFS Share Settings","text":"Parameter Value Path <code>/mnt/lab-pool/lab-backups</code> Mapall User <code>root</code> Mapall Group <code>root</code> Authorized Host <code>10.30.0.2</code> (PBS)"},{"location":"backups/#2-mount-nfs-in-pbs","title":"2. Mount NFS in PBS","text":""},{"location":"backups/#install-nfs-client-packages","title":"Install NFS client packages","text":"<pre><code>apt update &amp;&amp; apt install nfs-common -y\n</code></pre>"},{"location":"backups/#mount-test-optional","title":"Mount test (optional)","text":"<pre><code>mkdir -p /mnt/nfs-truenas\nmount -t nfs 10.30.0.3:/mnt/lab-pool/lab-backups /mnt/nfs-truenas\n</code></pre>"},{"location":"backups/#3-add-nfs-datastore-to-pbs","title":"3. Add NFS Datastore to PBS","text":"<p>In PBS UI:</p> <ol> <li>Go to Datastore &gt; Add.</li> <li>Type: NFS</li> <li>ID: <code>truenas-nfs</code></li> <li>Server: <code>10.30.0.3</code></li> <li>Export: <code>/mnt/lab-pool/lab-backups</code></li> <li>Mount: <code>Always</code></li> </ol> <p>It should now appear under <code>Datastores</code> and be available for backup tasks.</p>"},{"location":"backups/#4-backup-job-configuration","title":"4. Backup Job Configuration","text":"<p>From Proxmox VE nodes (<code>ve1</code> and <code>ve2</code>):</p> <ul> <li>Each VM or CT is assigned a schedule pointing to PBS.</li> <li>PBS stores the data on the mounted NFS export.</li> <li>Compression: ZSTD</li> <li>Schedule: daily / nightly</li> </ul>"},{"location":"backups/#5-verification","title":"5. Verification","text":"<ul> <li>Ensure PBS has access to <code>10.30.0.3</code></li> <li>Verify mounts via: <pre><code>df -h | grep nfs\n</code></pre></li> <li>Validate from PBS GUI under Datastore Status</li> </ul>"},{"location":"backups/#result","title":"Result","text":"<ul> <li>Backups are securely stored in TrueNAS over NFS.</li> <li>Redundancy and snapshots can be handled from the TrueNAS pool.</li> <li>Clean separation between compute and storage.</li> </ul>"},{"location":"containers/","title":"Docker CE &amp; Compose Installation \u2013 Debian 12","text":"<p>This guide documents the complete installation of Docker CE and Docker Compose (plugin version) on a minimal Debian 12 system.</p>"},{"location":"containers/#1-system-preparation","title":"1. System Preparation","text":"<pre><code>apt update &amp;&amp; apt upgrade -y\napt install sudo curl vim net-tools -y\n</code></pre>"},{"location":"containers/#2-install-docker","title":"2. Install Docker","text":"<pre><code>sudo apt install ca-certificates curl gnupg -y\nsudo install -d -m0755 /etc/apt/keyrings\n\ncurl -fsSL https://download.docker.com/linux/debian/gpg \\\n  | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \\\nhttps://download.docker.com/linux/debian \\\n$(. /etc/os-release &amp;&amp; echo $VERSION_CODENAME) stable\" \\\n  | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt update\nsudo apt install \\\n  docker-ce docker-ce-cli containerd.io \\\n  docker-buildx-plugin docker-compose-plugin -y\n</code></pre>"},{"location":"containers/#3-start-and-enable-docker","title":"3. Start and Enable Docker","text":"<pre><code>sudo systemctl enable docker\nsudo systemctl start docker\n</code></pre>"},{"location":"containers/#4-test-docker","title":"4. Test Docker","text":"<pre><code>docker run hello-world\n</code></pre>"},{"location":"containers/#result","title":"Result","text":"<p>Docker is installed with Compose support and ready for container deployment.</p>"},{"location":"containers/#portainer-ce-deployment-vesta-lab","title":"Portainer CE Deployment \u2013 Vesta Lab","text":"<p>This document details the deployment of Portainer Community Edition as the main management UI for Docker in the Vesta Lab.</p>"},{"location":"containers/#host-info","title":"Host Info","text":"<ul> <li>Node: <code>docker-ve1</code></li> <li>OS: Debian 12</li> <li>Docker installed: Yes</li> <li>Network: VLAN 20 \u2013 <code>10.20.0.0/24</code></li> <li>Portainer IP: <code>http://10.20.0.2:9000</code></li> </ul>"},{"location":"containers/#1-volume-preparation","title":"1. Volume Preparation","text":""},{"location":"containers/#option-a-local-volume","title":"Option A: Local Volume","text":"<pre><code>docker volume create portainer_data\n</code></pre>"},{"location":"containers/#option-b-nfs-persistent-volume","title":"Option B: NFS Persistent Volume","text":"<pre><code>mkdir -p /mnt/truenas_nfs/containers/portainer_data\necho \"10.30.0.3:/mnt/vesta-core/storage/lab/containers/portainer_data \\\n /mnt/truenas_nfs/containers/portainer_data nfs defaults,_netdev 0 0\" \\\n  &gt;&gt; /etc/fstab\nmount -a\n</code></pre>"},{"location":"containers/#2-deploy-portainer-ce","title":"2. Deploy Portainer CE","text":"<pre><code>docker run -d \\\n  --name portainer \\\n  -p 9000:9000 \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v portainer_data:/data \\\n  --restart=always \\\n  portainer/portainer-ce\n</code></pre> <p>Once deployed, visit <code>http://10.20.0.2:9000</code> to configure the initial admin user.</p>"},{"location":"containers/#3-notes","title":"3. Notes","text":"<ul> <li>Portainer manages local Docker volumes and containers.</li> <li>Accessible only from VLAN 20 or via Tailscale VPN.</li> <li>Recommended to back up the <code>/data</code> volume regularly.</li> </ul>"},{"location":"containers/#result_1","title":"Result","text":"<p>Portainer CE is running and configured as the primary UI to manage container services across the lab infrastructure.</p>"},{"location":"containers/#vaultwarden-docker-compose-deployment","title":"Vaultwarden \u2013 Docker Compose Deployment","text":"<p>This document describes how Vaultwarden (a lightweight Bitwarden-compatible server) is deployed in the Vesta Lab using Docker Compose.</p>"},{"location":"containers/#host-info_1","title":"Host Info","text":"<ul> <li>Hostname: <code>docker-ve1</code></li> <li>IP: <code>10.20.0.2</code></li> <li>Network: VLAN 20 \u2013 Services</li> <li>Domain: <code>https://vault.vestasec.com</code></li> <li>Reverse Proxy: Managed by NPM (Nginx Proxy Manager)</li> </ul>"},{"location":"containers/#1-docker-compose-file","title":"1. Docker Compose File","text":"<pre><code>version: \"3.9\"\nservices:\n  vaultwarden:\n    image: vaultwarden/server:latest\n    container_name: vaultwarden\n    restart: unless-stopped\n    environment:\n      DOMAIN: \"https://vault.vestasec.com\"\n    volumes:\n      - ./vw-data:/data\n    ports:\n      - 8222:80\n</code></pre> <p>Replace volume path and port as needed if reverse proxy is used.</p>"},{"location":"containers/#2-directory-structure","title":"2. Directory Structure","text":"<pre><code>/opt/vaultwarden/\n\u251c\u2500\u2500 docker-compose.yml\n\u2514\u2500\u2500 vw-data/            # Persistent data volume\n</code></pre> <p>Create the data directory:</p> <pre><code>mkdir -p /opt/vaultwarden/vw-data\ncd /opt/vaultwarden\ndocker compose up -d\n</code></pre>"},{"location":"containers/#3-reverse-proxy-integration","title":"3. Reverse Proxy Integration","text":"<p>In Nginx Proxy Manager (NPM):</p> <ul> <li>Create a Proxy Host:</li> <li>Domain: <code>vault.vestasec.com</code></li> <li>Forward IP: <code>10.20.0.2</code></li> <li>Forward Port: <code>8222</code></li> <li>Enable SSL via Let's Encrypt (DNS-01)</li> </ul>"},{"location":"containers/#result_2","title":"Result","text":"<p>Vaultwarden is now available at <code>https://vault.vestasec.com</code> behind a secure NPM proxy, with persistent storage and restart policy in place.</p>"},{"location":"containers/#gitlab-ce-docker-compose-deployment","title":"GitLab CE \u2013 Docker Compose Deployment","text":"<p>This document describes how GitLab Community Edition is deployed in the Vesta Lab using Docker Compose.</p>"},{"location":"containers/#host-info_2","title":"Host Info","text":"<ul> <li>Hostname: <code>docker-ve1</code></li> <li>IP: <code>10.20.0.2</code></li> <li>Network: VLAN 20 \u2013 Services</li> <li>Domain: <code>https://gitlab.vestasec.com</code></li> <li>Reverse Proxy: Nginx Proxy Manager (NPM)</li> </ul>"},{"location":"containers/#1-docker-compose-file_1","title":"1. Docker Compose File","text":"<pre><code>version: \"3.9\"\nservices:\n  gitlab:\n    image: gitlab/gitlab-ce:latest\n    container_name: gitlab\n    ports:\n      - \"2424:22\"     # SSH\n      - \"8929:80\"     # HTTP (internal use)\n    volumes:\n      - ./config:/etc/gitlab\n      - ./logs:/var/log/gitlab\n      - ./data:/var/opt/gitlab\n    networks:\n      - npm_default\n    restart: unless-stopped\n\nnetworks:\n  npm_default:\n    external: true\n</code></pre> <p>Make sure <code>npm_default</code> network exists (created by NPM container).</p>"},{"location":"containers/#2-directory-structure_1","title":"2. Directory Structure","text":"<pre><code>/opt/gitlab/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 config/\n\u251c\u2500\u2500 logs/\n\u2514\u2500\u2500 data/\n</code></pre> <p>Prepare directories:</p> <pre><code>mkdir -p /opt/gitlab/{config,logs,data}\ncd /opt/gitlab\ndocker compose up -d\n</code></pre>"},{"location":"containers/#3-reverse-proxy-integration_1","title":"3. Reverse Proxy Integration","text":"<p>In NPM:</p> <ul> <li>Domain: <code>gitlab.vestasec.com</code></li> <li>Forward IP: <code>10.20.0.2</code></li> <li>Forward Port: <code>8929</code></li> <li>SSL via Let's Encrypt (DNS-01)</li> <li>Enable WebSocket support (optional)</li> </ul>"},{"location":"containers/#result_3","title":"Result","text":"<p>GitLab CE is now available at <code>https://gitlab.vestasec.com</code>, running behind NPM with persistent volumes and integrated SSH access via port 2424.</p>"},{"location":"containers/#nginx-proxy-manager-dns-ssl-integration","title":"Nginx Proxy Manager \u2013 DNS + SSL Integration","text":"<p>This document describes the deployment of Nginx Proxy Manager (NPM) in the Vesta Lab and the DNS-01 challenge configuration for automatic SSL.</p>"},{"location":"containers/#host-info_3","title":"Host Info","text":"<ul> <li>Hostname: <code>docker-ve1</code></li> <li>IP: <code>10.20.0.2</code></li> <li>Network: VLAN 20 \u2013 Services</li> <li>Domain: <code>*.vestasec.com</code></li> <li>NPM Port: <code>http://10.20.0.2:9001</code></li> </ul>"},{"location":"containers/#1-docker-compose-file_2","title":"1. Docker Compose File","text":"<pre><code>version: \"3.9\"\nservices:\n  npm:\n    image: jc21/nginx-proxy-manager:latest\n    container_name: npm\n    restart: unless-stopped\n    ports:\n      - \"9001:81\"     # Admin UI\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./data:/data\n      - ./letsencrypt:/etc/letsencrypt\n    networks:\n      - default\n</code></pre>"},{"location":"containers/#2-directory-setup","title":"2. Directory Setup","text":"<pre><code>/opt/npm/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 data/\n\u2514\u2500\u2500 letsencrypt/\n</code></pre> <p>Launch:</p> <pre><code>mkdir -p /opt/npm/{data,letsencrypt}\ncd /opt/npm\ndocker compose up -d\n</code></pre>"},{"location":"containers/#3-dns-01-challenge-cloudflare","title":"3. DNS-01 Challenge (Cloudflare)","text":""},{"location":"containers/#requirements","title":"Requirements","text":"<ul> <li>API Token with permissions for DNS zone edit</li> <li>Cloudflare DNS record:  </li> <li>Type A: <code>*</code> \u2192 <code>10.20.0.2</code></li> </ul>"},{"location":"containers/#configuration","title":"Configuration","text":"<p>In NPM UI: 1. Go to SSL Certificates \u2192 Add 2. Use <code>DNS Challenge</code> 3. Select provider: Cloudflare 4. Paste your API token 5. Save \u2192 NPM auto-generates and renews wildcard cert</p>"},{"location":"containers/#result_4","title":"Result","text":"<p>NPM is running on <code>http://10.20.0.2:9001</code>, issuing valid SSL certificates for all internal services using DNS-01.</p>"},{"location":"containers/#docker-node-setup-docker-ve1","title":"Docker Node Setup \u2013 docker-ve1","text":""},{"location":"containers/#1-vm-configuration","title":"1. VM Configuration","text":"<p>This VM was created in Proxmox with the following parameters:</p> <ul> <li>Name: <code>docker-ve1</code></li> <li>Node: <code>ve1</code></li> <li>vCPU: 2 (1 socket)</li> <li>RAM: 4 GB</li> <li>Disk: 32 GB (VirtIO, SCSI)</li> <li>Bridge: <code>vmbr0</code></li> <li>VLAN Tag: 20</li> <li>IP: <code>10.20.0.2</code></li> <li>Gateway: <code>10.20.0.1</code></li> <li>DNS: <code>10.0.0.102</code>, <code>1.1.1.1</code></li> </ul>"},{"location":"containers/#2-operating-system","title":"2. Operating System","text":"<ul> <li>Debian 12 (Bookworm) minimal installation using netinst ISO.</li> </ul>"},{"location":"containers/#3-system-update-essentials","title":"3. System Update &amp; Essentials","text":"<pre><code>apt update &amp;&amp; apt upgrade -y\napt install sudo curl vim net-tools -y\n</code></pre>"},{"location":"containers/#4-docker-ce-compose-installation","title":"4. Docker CE &amp; Compose Installation","text":"<pre><code>sudo apt install ca-certificates curl gnupg -y\nsudo install -d -m0755 /etc/apt/keyrings\n\ncurl -fsSL https://download.docker.com/linux/debian/gpg \\\n  | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \\\nhttps://download.docker.com/linux/debian \\\n$(. /etc/os-release &amp;&amp; echo $VERSION_CODENAME) stable\" \\\n  | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt update\nsudo apt install \\\n  docker-ce docker-ce-cli containerd.io \\\n  docker-buildx-plugin docker-compose-plugin -y\n\nsudo systemctl enable docker\nsudo systemctl start docker\n</code></pre>"},{"location":"containers/#test-docker-installation","title":"Test Docker installation:","text":"<pre><code>docker run hello-world\n</code></pre>"},{"location":"containers/#5-deploying-portainer","title":"5. Deploying Portainer","text":""},{"location":"containers/#option-a-local-volume_1","title":"Option A: Local Volume","text":"<pre><code>docker volume create portainer_data\n</code></pre>"},{"location":"containers/#option-b-nfs-volume","title":"Option B: NFS Volume","text":"<pre><code>mkdir -p /mnt/truenas_nfs/containers/portainer_data\necho \"10.30.0.3:/mnt/vesta-core/storage/lab/containers/portainer_data \\\n /mnt/truenas_nfs/containers/portainer_data nfs defaults,_netdev 0 0\" \\\n  &gt;&gt; /etc/fstab\nmount -a\n</code></pre>"},{"location":"containers/#run-portainer","title":"Run Portainer","text":"<pre><code>docker run -d \\\n  --name portainer \\\n  -p 9000:9000 \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v portainer_data:/data \\\n  --restart=always \\\n  portainer/portainer-ce\n</code></pre> <p>At this point, Portainer is available at http://10.20.0.2:9000</p>"},{"location":"credits/","title":"Credits &amp; Metadata","text":"<p>This documentation is part of the Vesta Technical Lab, maintained and developed by:</p> <ul> <li>Author: Ignacio Fernandez</li> <li>Company: Vesta Security LATAM S.A.</li> <li>Website: https://vestasec.com</li> <li>Repository: GitHub - vesta-lab</li> </ul>"},{"location":"credits/#documentation-structure","title":"Documentation Structure","text":"<p>This lab is divided into technical modules documented under <code>docs/</code>, supported by: - Visual diagrams under <code>assets/diagrams/</code> - Real system screenshots under <code>assets/screenshots/</code> - Scripts for installation and automation under <code>scripts/</code> - Reusable templates in <code>templates/</code> - Configuration backups and files under <code>exports/</code></p>"},{"location":"credits/#versioning","title":"Versioning","text":"<ul> <li>Documentation version: 1.0</li> <li>Last updated: June 2025</li> </ul> <p>This repository is licensed under the MIT License unless otherwise stated.</p>"},{"location":"internal_apps/","title":"GitLab CE \u2013 Internal Service Overview","text":"<p>GitLab CE is deployed in the Vesta Lab as an internal code management and CI/CD platform.</p>"},{"location":"internal_apps/#configuration","title":"Configuration","text":"<ul> <li>Domain: <code>gitlab.vestasec.com</code></li> <li>Host IP: <code>10.20.0.2</code></li> <li>Reverse Proxy: Nginx Proxy Manager</li> <li>SSH Port: <code>2424</code></li> <li>HTTP Port (internal): <code>8929</code></li> </ul>"},{"location":"internal_apps/#use-cases","title":"Use Cases","text":"<ul> <li>Private Git repos for Docker Compose, scripts, and Odoo modules</li> <li>CI pipelines (future use)</li> <li>Centralized version control for all infrastructure code</li> </ul>"},{"location":"internal_apps/#access","title":"Access","text":"<p>Accessible only: - From VLAN 20 - Via VPN (Tailscale) - Through domain <code>https://gitlab.vestasec.com</code></p>"},{"location":"internal_apps/#backups","title":"Backups","text":"<ul> <li>GitLab data volume is mapped and backed up via PBS</li> <li>External Git repo backups planned</li> </ul>"},{"location":"internal_apps/#vaultwarden-internal-password-manager","title":"Vaultwarden \u2013 Internal Password Manager","text":"<p>Vaultwarden is deployed in the Vesta Lab as a self-hosted, lightweight alternative to Bitwarden for managing credentials and secrets.</p>"},{"location":"internal_apps/#access_1","title":"Access","text":"<ul> <li>Domain: <code>vault.vestasec.com</code></li> <li>IP: <code>10.20.0.2</code></li> <li>Reverse Proxy: NPM with DNS-01 SSL</li> <li>Enforced HTTPS only</li> </ul>"},{"location":"internal_apps/#security","title":"Security","text":"<ul> <li>Access restricted to:</li> <li>VLAN 20</li> <li>VPN clients via Tailscale</li> <li>Admin password stored securely outside the container</li> <li>2FA enabled per user</li> </ul>"},{"location":"internal_apps/#storage","title":"Storage","text":"<ul> <li>Data stored in volume: <code>./vw-data:/data</code></li> <li>Persistent and backed up via NFS to TrueNAS</li> <li>Daily snapshot through PBS integration</li> </ul>"},{"location":"internal_apps/#use-cases_1","title":"Use Cases","text":"<ul> <li>Store internal service credentials</li> <li>Share credentials securely across lab systems</li> <li>Integrate with browser extensions locally</li> </ul>"},{"location":"internal_apps/#adguard-home-docker-deployment","title":"AdGuard Home \u2013 Docker Deployment","text":"<p>AdGuard Home is used in the Vesta Lab to block ads and malicious domains across internal clients.</p>"},{"location":"internal_apps/#host-info","title":"Host Info","text":"<ul> <li>Node: <code>docker-ve2</code></li> <li>IP: <code>10.20.0.3</code></li> <li>Port: <code>8053</code> (DNS)</li> <li>Web UI: <code>http://10.20.0.3:3002</code></li> <li>VLAN: 20 (services)</li> </ul>"},{"location":"internal_apps/#deployment-docker","title":"Deployment (Docker)","text":"<pre><code>docker run -d \\\n  --name adguard \\\n  -v /opt/adguard/work:/opt/adguardhome/work \\\n  -p 3002:3000 \\\n  -p 8053:53/tcp \\\n  -p 8053:53/udp \\\n  --restart=unless-stopped \\\n  adguard/adguardhome:latest --setup\n</code></pre> <p>Complete initial setup at <code>http://10.20.0.3:3002</code></p>"},{"location":"internal_apps/#dns-configuration","title":"DNS Configuration","text":"<ul> <li>Set <code>10.20.0.3</code> as primary DNS server in DHCP</li> <li>Optionally route <code>.local</code> queries to AdGuard</li> </ul>"},{"location":"internal_apps/#result","title":"Result","text":"<p>AdGuard is now resolving DNS and filtering ads for internal lab devices.</p>"},{"location":"internal_apps/#bookstack-technical-wiki-docker-deployment","title":"BookStack \u2013 Technical Wiki (Docker Deployment)","text":"<p>BookStack is used as a wiki and documentation platform in the Vesta Lab.</p>"},{"location":"internal_apps/#host-info_1","title":"Host Info","text":"<ul> <li>Node: <code>docker-ve2</code></li> <li>IP: <code>10.20.0.3</code></li> <li>Port: <code>8080</code> (internal)</li> <li>Domain: <code>wiki.vestasec.com</code></li> <li>Reverse Proxy: NPM</li> </ul>"},{"location":"internal_apps/#docker-compose-example","title":"Docker Compose (example)","text":"<pre><code>version: \"3\"\nservices:\n  bookstack:\n    image: linuxserver/bookstack\n    container_name: bookstack\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - DB_HOST=mariadb\n      - DB_USER=bookstack\n      - DB_PASS=&lt;REPLACE_WITH_SECURE_PASSWORD&gt;\n      - DB_DATABASE=bookstackapp\n    volumes:\n      - ./config:/config\n    ports:\n      - 8080:80\n    restart: unless-stopped\n\n  mariadb:\n    image: mariadb\n    container_name: mariadb\n    environment:\n      - MYSQL_ROOT_PASSWORD=&lt;REPLACE_WITH_SECURE_PASSWORD&gt;\n      - MYSQL_DATABASE=bookstackapp\n      - MYSQL_USER=bookstack\n      - MYSQL_PASSWORD=&lt;REPLACE_WITH_SECURE_PASSWORD&gt;\n    volumes:\n      - ./db:/var/lib/mysql\n    restart: unless-stopped\n</code></pre>"},{"location":"internal_apps/#result_1","title":"Result","text":"<p>Accessible at <code>https://wiki.vestasec.com</code> with full web-based editing and user access control.</p>"},{"location":"monitoring/","title":"Prometheus Setup \u2013 Vesta Lab","text":"<p>Prometheus collects metrics from exporters in the Vesta Lab and makes them available to Grafana.</p>"},{"location":"monitoring/#host-info","title":"Host Info","text":"<ul> <li>Node: <code>docker-ve2</code></li> <li>IP: <code>10.20.0.3</code></li> <li>Port: <code>9090</code></li> </ul>"},{"location":"monitoring/#1-directory-structure","title":"1. Directory Structure","text":"<pre><code>/opt/monitoring/prometheus/\n\u251c\u2500\u2500 prometheus.yml\n</code></pre>"},{"location":"monitoring/#2-basic-prometheusyml","title":"2. Basic prometheus.yml","text":"<pre><code>global:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['localhost:9090']\n\n  - job_name: 've1-proxmox'\n    static_configs:\n      - targets: ['10.10.0.2:9100']\n\n  - job_name: 've2-proxmox'\n    static_configs:\n      - targets: ['10.10.0.3:9100']\n</code></pre>"},{"location":"monitoring/#3-run-prometheus","title":"3. Run Prometheus","text":"<pre><code>docker run -d \\\n  --name=prometheus \\\n  -p 9090:9090 \\\n  -v /opt/monitoring/prometheus:/etc/prometheus \\\n  prom/prometheus\n</code></pre>"},{"location":"monitoring/#result","title":"Result","text":"<p>Prometheus is collecting data from all node exporters and exposing metrics to Grafana.</p>"},{"location":"monitoring/#node-exporter-deployment-vesta-lab","title":"Node Exporter Deployment \u2013 Vesta Lab","text":"<p>Node Exporter is installed on each Proxmox node to provide system-level metrics to Prometheus.</p>"},{"location":"monitoring/#installation-on-each-node","title":"Installation (on each node)","text":"<pre><code>docker run -d \\\n  --name=node-exporter \\\n  --net=\"host\" \\\n  --pid=\"host\" \\\n  --restart always \\\n  -v \"/:/host:ro,rslave\" \\\n  quay.io/prometheus/node-exporter:latest \\\n  --path.rootfs=/host\n</code></pre> <ul> <li>Node <code>ve1</code>: <code>10.10.0.2:9100</code></li> <li>Node <code>ve2</code>: <code>10.10.0.3:9100</code></li> </ul>"},{"location":"monitoring/#result_1","title":"Result","text":"<p>Each node is exposing metrics to Prometheus on port <code>9100</code>.</p>"},{"location":"monitoring/#grafana-configuration-vesta-lab","title":"Grafana Configuration \u2013 Vesta Lab","text":"<p>Grafana is used as the main visualization layer on top of Prometheus metrics.</p>"},{"location":"monitoring/#host-info_1","title":"Host Info","text":"<ul> <li>Node: <code>docker-ve2</code></li> <li>IP: <code>10.20.0.3</code></li> <li>Port: <code>3000</code></li> <li>Default credentials: <code>admin / admin</code></li> </ul>"},{"location":"monitoring/#deployment","title":"Deployment","text":"<pre><code>docker run -d \\\n  --name=grafana \\\n  -p 3000:3000 \\\n  -v grafana_data:/var/lib/grafana \\\n  --restart=always \\\n  grafana/grafana-oss\n</code></pre>"},{"location":"monitoring/#configuration-steps","title":"\ufe0f Configuration Steps","text":"<ol> <li>Access: <code>http://10.20.0.3:3000</code></li> <li>Add Prometheus as data source: <code>http://10.20.0.3:9090</code></li> <li>Import dashboard: Node Exporter Full (ID: 1860)</li> </ol>"},{"location":"monitoring/#result_2","title":"Result","text":"<p>Grafana is connected to Prometheus and visualizing node metrics.</p>"},{"location":"monitoring/#uptime-kuma-service-monitoring-setup","title":"Uptime Kuma \u2013 Service Monitoring Setup","text":"<p>Uptime Kuma is deployed in the Vesta Lab to monitor the availability of internal and external services via HTTP, TCP, and ICMP.</p>"},{"location":"monitoring/#host-info_2","title":"Host Info","text":"<ul> <li>Node: <code>docker-ve2</code></li> <li>IP: <code>10.20.0.3</code></li> <li>Port: <code>8280</code></li> <li>VLAN: 20 (services)</li> </ul>"},{"location":"monitoring/#deployment-docker","title":"Deployment (Docker)","text":"<pre><code>docker volume create uptime_kuma_data\n\ndocker run -d \\\n  --name uptime-kuma \\\n  -p 8280:3001 \\\n  -v uptime_kuma_data:/app/data \\\n  --restart=always \\\n  louislam/uptime-kuma:latest\n</code></pre>"},{"location":"monitoring/#usage","title":"Usage","text":"<ul> <li>Access: <code>http://10.20.0.3:8280</code></li> <li>Create monitors:</li> <li><code>https://vault.vestasec.com</code></li> <li><code>https://gitlab.vestasec.com</code></li> <li><code>http://10.10.0.2:8006</code> (Proxmox VE1)</li> <li><code>http://10.10.0.3:8006</code> (Proxmox VE2)</li> </ul>"},{"location":"monitoring/#result_3","title":"Result","text":"<p>Uptime Kuma is now monitoring the uptime and latency of lab services with visual dashboards and alerts.</p>"},{"location":"network/","title":"MikroTik VLAN &amp; Routing Configuration","text":""},{"location":"network/#router-model","title":"Router Model","text":"<ul> <li>MikroTik hEX RB750Gr3</li> <li>RouterOS v7+</li> <li>Access: WinBox, WebFig, SSH</li> </ul>"},{"location":"network/#interfaces-and-bridge","title":"Interfaces and Bridge","text":"<pre><code>ether1: WAN uplink\nether2-ether5: LAN / trunk ports\nbridge: main bridge with VLAN awareness\n</code></pre>"},{"location":"network/#vlans-defined","title":"VLANs Defined","text":"VLAN Name Subnet Purpose 10 mgmt 10.10.0.0/24 Proxmox nodes 20 services 10.20.0.0/24 Docker, NPM 30 storage 10.30.0.0/24 PBS, TrueNAS 40 iot 10.40.0.0/24 IoT devices 50 guest 10.50.0.0/24 Guest clients"},{"location":"network/#dhcp-server-per-vlan","title":"DHCP Server per VLAN","text":"<p>Each VLAN has its own DHCP server and IP pool.</p>"},{"location":"network/#static-routes","title":"Static Routes","text":"<p>The MikroTik routes between VLANs and acts as the default gateway for all subnets.</p>"},{"location":"network/#nat-firewall","title":"\ufe0f NAT &amp; Firewall","text":"<ul> <li>NAT rule: masquerade for all outbound traffic via WAN</li> <li>Firewall: default drop + accepted rules per interface/vlan</li> </ul>"},{"location":"network/#configuration-file","title":"Configuration File","text":"<p>See <code>mikrotik/config_files/full_config.rsc</code> for the exported configuration of the lab router.</p>"},{"location":"network/#vpn-gateway-tailscale-setup-docker-ve2","title":"VPN Gateway \u2013 Tailscale Setup (docker-ve2)","text":"<p>This VPN Gateway provides secure remote access to all services in the Vesta Lab via Tailscale.</p>"},{"location":"network/#infrastructure","title":"Infrastructure","text":"<ul> <li>Hostname: <code>vpn-gateway</code></li> <li>Location: Docker container on <code>docker-ve2</code></li> <li>IP: <code>10.20.0.3</code></li> <li>VLAN: 20 (services)</li> <li>ACL Tag: <code>tag:docker</code></li> <li>Auth: Pre-authorized <code>TS_AUTHKEY</code></li> </ul>"},{"location":"network/#docker-deployment","title":"Docker Deployment","text":"<pre><code>docker run -d \\\n  --name=tailscale \\\n  --cap-add=NET_ADMIN \\\n  --device=/dev/net/tun \\\n  -e TS_AUTHKEY=\"tskey-...\" \\\n  -e TS_ROUTES=\"10.0.0.0/8\" \\\n  -e TS_EXTRA_ARGS=\"--advertise-tags=tag:docker\" \\\n  -v tailscale_data:/var/lib/tailscale \\\n  --restart=always \\\n  tailscale/tailscale\n</code></pre> <p>Replace <code>tskey-...</code> with your pre-authorized key from the Tailscale admin console.</p>"},{"location":"network/#acl-configuration","title":"ACL Configuration","text":"<p>ACLs are managed via the Tailscale admin panel:</p> <pre><code>{\n  \"groups\": {\n    \"group:admin\": [\"info@vestasec.com\"]\n  },\n  \"tagOwners\": {\n    \"tag:docker\": [\"autogroup:admin\"]\n  },\n  \"acls\": [\n    {\n      \"action\": \"accept\",\n      \"src\": [\"*\"],\n      \"dst\": [\"*:*\"]\n    }\n  ]\n}\n</code></pre> <p>This setup allows full unrestricted access from any approved client to any subnet, including internal lab services.</p>"},{"location":"network/#verification","title":"Verification","text":"<ul> <li>Access <code>vpn-gateway</code> from Tailscale Console</li> <li>Ensure it shows <code>tag:docker</code> and status \"Active\"</li> <li>Confirm route advertisement covers lab subnets</li> </ul>"},{"location":"network/#result","title":"Result","text":"<p>Remote access to the full lab infrastructure via Tailscale is now secure and available across devices.</p>"},{"location":"network/#vesta-lab-vlan-configuration","title":"Vesta Lab \u2013 VLAN Configuration","text":"<p>VLANs are used in the Vesta Lab to separate network traffic logically and securely. All VLANs are trunked through the MikroTik router and tagged appropriately on Proxmox bridges and VM interfaces.</p>"},{"location":"network/#vlan-table","title":"VLAN Table","text":"VLAN ID Name Subnet Purpose 10 mgmt 10.10.0.0/24 Proxmox VE, monitoring 20 services 10.20.0.0/24 Docker, Portainer, NPM 30 storage 10.30.0.0/24 PBS, TrueNAS, NFS 40 iot 10.40.0.0/24 Future IoT devices 50 guest 10.50.0.0/24 Guest WiFi, external users"},{"location":"network/#trunk-configuration-proxmox","title":"Trunk Configuration (Proxmox)","text":"<p>Bridge <code>vmbr0</code> on each Proxmox node includes VLAN awareness:</p> <pre><code>bridge-vlan-aware yes\nbridge-vids 2-4094\n</code></pre> <p>Each VM or container is assigned a VLAN tag using <code>vmbr0.X</code>, for example:</p> <pre><code>auto vmbr0.10\niface vmbr0.10 inet static\n  address 10.10.0.2/24\n  gateway 10.10.0.1\n</code></pre>"},{"location":"network/#mikrotik-port-configuration","title":"MikroTik Port Configuration","text":"<ul> <li>ether1: WAN</li> <li>ether2\u2013ether5: trunk ports to Proxmox nodes and switches</li> <li>Bridge interface carries all VLANs</li> <li>DHCP servers per VLAN</li> </ul>"},{"location":"network/#benefits","title":"Benefits","text":"<ul> <li>Isolation between infrastructure layers</li> <li>Reduced broadcast domain</li> <li>Improved security posture</li> <li>Simplified firewall rule logic</li> </ul>"},{"location":"network/#result_1","title":"Result","text":"<p>All core services operate in isolated VLANs with centralized routing, DHCP and firewalling via MikroTik.</p>"},{"location":"network/#mikrotik-firewall-nat-configuration-vesta-lab","title":"MikroTik Firewall &amp; NAT Configuration \u2013 Vesta Lab","text":"<p>The following rules and NAT configuration are used to secure the lab while allowing functional access between VLANs and out to the Internet.</p>"},{"location":"network/#default-policy","title":"Default Policy","text":"<ul> <li>Input Chain: Drop all unless explicitly allowed</li> <li>Forward Chain: Accept all inter-VLAN unless filtered</li> <li>Output Chain: Accept</li> </ul>"},{"location":"network/#nat-rules","title":"NAT Rules","text":"<pre><code>/ip firewall nat\nadd chain=srcnat out-interface=ether1 action=masquerade comment=\"NAT for WAN access\"\n</code></pre> <p>This rule enables Internet access for all VLANs through the main WAN interface (ether1).</p>"},{"location":"network/#input-chain-rules","title":"Input Chain Rules","text":"<pre><code>/ip firewall filter\nadd chain=input action=accept connection-state=established,related comment=\"Allow established\"\nadd chain=input action=accept protocol=icmp comment=\"Allow ICMP\"\nadd chain=input action=accept in-interface=bridge src-address=10.10.0.0/24 comment=\"Allow mgmt subnet\"\nadd chain=input action=drop comment=\"Drop all else\"\n</code></pre>"},{"location":"network/#forwarding-inter-vlan-traffic","title":"Forwarding &amp; Inter-VLAN Traffic","text":"<p>All VLANs are allowed to route between each other by default. This can be restricted further per use case using additional forward chain filters.</p> <p>Example: block IoT (VLAN 40) from accessing mgmt (VLAN 10): <pre><code>add chain=forward action=drop src-address=10.40.0.0/24 dst-address=10.10.0.0/24\n</code></pre></p>"},{"location":"network/#security-notes","title":"\ufe0f Security Notes","text":"<ul> <li>WinBox and SSH are only allowed from the management VLAN (10.10.0.0/24)</li> <li>Remote admin interfaces should be disabled on guest-facing VLANs</li> <li>Service ports (UPnP, DNS, FTP) are disabled by default</li> </ul>"},{"location":"network/#result_2","title":"Result","text":"<p>A hardened firewall configuration that protects the router and core lab infrastructure while enabling controlled inter-VLAN communication and Internet access.</p>"},{"location":"storage/","title":"TrueNAS SCALE \u2013 Dataset and Storage Design","text":"<p>This document describes the internal dataset structure, permission model, and service usage within the TrueNAS instance in the Vesta Lab.</p>"},{"location":"storage/#host-info","title":"Host Info","text":"<ul> <li>Hostname: <code>truenas</code></li> <li>IP: <code>10.30.0.3</code></li> <li>VLAN: 30 (storage)</li> <li>Pool: <code>lab-pool</code></li> </ul>"},{"location":"storage/#dataset-structure","title":"Dataset Structure","text":"<pre><code>lab-pool/\n\u251c\u2500\u2500 lab-backups/         # NFS export used by PBS\n\u251c\u2500\u2500 storage/\n\u2502   \u251c\u2500\u2500 lab/\n\u2502   \u2502   \u251c\u2500\u2500 containers/  # Portainer volumes (optional)\n\u2502   \u2502   \u2514\u2500\u2500 scripts/     # Automation scripts\n\u2502   \u2514\u2500\u2500 vesta-core/\n\u2502       \u251c\u2500\u2500 docs/\n\u2502       \u251c\u2500\u2500 clients/\n\u2502       \u2514\u2500\u2500 internal/\n</code></pre>"},{"location":"storage/#permissions","title":"Permissions","text":"<ul> <li>ACL disabled (POSIX mode)</li> <li><code>Mapall</code> user: <code>root</code></li> <li>Used for NFS exports to PBS and Docker nodes</li> <li>Access allowed: <code>10.30.0.2</code> (PBS), <code>10.20.0.2</code> (Docker)</li> </ul>"},{"location":"storage/#usage","title":"Usage","text":"<ul> <li>Export <code>lab-backups</code> to PBS via NFS</li> <li>Export <code>containers/</code> and <code>scripts/</code> to Docker via bind mount</li> <li>Shared folders visible over SMB when needed</li> </ul>"},{"location":"storage/#truenas-nfs-and-smb-configuration","title":"TrueNAS \u2013 NFS and SMB Configuration","text":"<p>This document explains the export of storage via NFS and SMB from TrueNAS to the rest of the lab infrastructure.</p>"},{"location":"storage/#nfs-export-lab-backups","title":"NFS Export: <code>lab-backups</code>","text":"<ul> <li>Path: <code>/mnt/lab-pool/lab-backups</code></li> <li>Enabled: Yes</li> <li>Permissions: POSIX, <code>Mapall user = root</code></li> <li>Allowed IPs: <code>10.30.0.2</code> (PBS)</li> </ul>"},{"location":"storage/#nfs-export-containers","title":"NFS Export: <code>containers/</code>","text":"<ul> <li>Path: <code>/mnt/lab-pool/storage/lab/containers</code></li> <li>Mount to Docker nodes via <code>/etc/fstab</code></li> <li>Used for persistent volumes (e.g. Portainer)</li> </ul>"},{"location":"storage/#smb-shares","title":"SMB Shares","text":"<ul> <li>Optional: enable for workstations</li> <li>Example share: <code>/mnt/lab-pool/storage/vesta-core/docs</code></li> <li>Permissions: user-level, <code>vestasec</code> account</li> </ul>"},{"location":"storage/#integration","title":"Integration","text":"<ul> <li>PBS \u2192 NFS <code>lab-backups</code></li> <li>Docker \u2192 NFS <code>containers/</code></li> <li>Windows clients \u2192 SMB shares</li> </ul>"},{"location":"templates/","title":"VM Templates Used in Vesta Lab","text":"<p>Using base VM templates ensures consistent deployment, fast provisioning, and automated scaling. Below are the most common templates used in the lab.</p>"},{"location":"templates/#1-debian-12-bookworm-netinst-template","title":"1. Debian 12 (Bookworm) \u2013 Netinst Template","text":""},{"location":"templates/#creation-steps","title":"Creation Steps","text":"<ol> <li> <p>Download the ISO: https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/</p> </li> <li> <p>Create VM in Proxmox:</p> </li> <li>1 vCPU, 1 GB RAM, 8 GB Disk (SCSI)</li> <li>Network: <code>vmbr0</code>, tag as needed</li> <li>BIOS: SeaBIOS, Machine: i440fx</li> <li>Boot ISO, install with minimal options</li> <li> <p>Configure static IP if needed</p> </li> <li> <p>After first boot: <pre><code>apt update &amp;&amp; apt upgrade -y\napt install sudo curl vim net-tools qemu-guest-agent -y\nsystemctl enable qemu-guest-agent\n</code></pre></p> </li> <li> <p>Clean up: <pre><code>apt clean\n</code></pre></p> </li> <li> <p>Shutdown and convert to template from Proxmox UI.</p> </li> </ol>"},{"location":"templates/#2-ubuntu-2204-cloud-init-image","title":"2. Ubuntu 22.04 Cloud-Init Image","text":""},{"location":"templates/#download-and-import","title":"Download and Import","text":"<pre><code>wget https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img\nqm create 9000 --name ubuntu-2204-cloud --memory 1024 --net0 virtio,bridge=vmbr0\nqm importdisk 9000 jammy-server-cloudimg-amd64.img local-lvm\nqm set 9000 --scsihw virtio-scsi-pci --scsi0 local-lvm:vm-9000-disk-0\nqm set 9000 --ide2 local-lvm:cloudinit\nqm set 9000 --boot c --bootdisk scsi0\nqm set 9000 --serial0 socket --vga serial0\n</code></pre> <p>Then use Cloud-Init in Proxmox to inject SSH key, hostname, IP, and packages.</p>"},{"location":"templates/#3-maintenance-recommendations","title":"3. Maintenance Recommendations","text":"<ul> <li>Regularly update and re-template to apply kernel and package fixes.</li> <li>Keep base template minimal: no extra services.</li> <li>Use Cloud-Init wherever possible for faster automation.</li> </ul>"},{"location":"templates/#result","title":"Result","text":"<p>Using lightweight templates saves time, ensures consistency, and helps automate service deployment across the lab.</p>"},{"location":"troubleshooting/","title":"Common Issues in Vesta Lab","text":"<p>Below are common technical issues encountered during setup and operation of the lab, along with verified solutions.</p>"},{"location":"troubleshooting/#1-pbs-datastore-path-not-empty","title":"1. PBS \u2013 Datastore Path Not Empty","text":"<p>Issue: PBS fails to add NFS export from TrueNAS with error <code>datastore path not empty</code>.</p> <p>Cause: The NFS mount already contains hidden files or previous mount attempts.</p> <p>Fix: 1. Unmount the directory:    <pre><code>umount /mnt/truenas-nfs\n</code></pre> 2. Remove contents manually:    <pre><code>rm -rf /mnt/truenas-nfs/*\n</code></pre> 3. Remount and retry from PBS UI.</p>"},{"location":"troubleshooting/#2-pbs-cannot-reach-truenas-nfs","title":"2. PBS \u2013 Cannot Reach TrueNAS NFS","text":"<p>Issue: PBS can't mount the NFS export even when config looks correct.</p> <p>Fix Checklist: - TrueNAS: Confirm <code>Mapall</code> is set to <code>root/root</code> - Confirm TrueNAS NFS Share allows host <code>10.30.0.2</code> - PBS: Run <code>showmount -e 10.30.0.3</code> to validate NFS exports - Confirm <code>nfs-common</code> is installed on PBS</p>"},{"location":"troubleshooting/#3-docker-node-dns-resolution-fails","title":"3. Docker Node \u2013 DNS Resolution Fails","text":"<p>Issue: Docker containers can't resolve DNS names.</p> <p>Fix: Add to <code>/etc/docker/daemon.json</code>: <pre><code>{\n  \"dns\": [\"10.0.0.102\", \"1.1.1.1\"]\n}\n</code></pre> Then restart Docker: <pre><code>systemctl restart docker\n</code></pre></p>"},{"location":"troubleshooting/#4-portainer-error-using-nfs-volume","title":"4. Portainer \u2013 Error Using NFS Volume","text":"<p>Issue: Portainer fails when mounting volume from TrueNAS.</p> <p>Fix: Ensure: - NFS path exists - <code>fstab</code> is properly mounted with <code>_netdev</code> option - Docker is restarted after mount</p>"},{"location":"troubleshooting/#5-proxmox-node-no-network-after-reboot","title":"5. Proxmox Node \u2013 No Network After Reboot","text":"<p>Issue: Static IP not working or VLAN missing.</p> <p>Fix: - Confirm <code>/etc/network/interfaces</code> has <code>bridge-vlan-aware yes</code> - VLAN must be defined (<code>vmbr0.10</code>, <code>vmbr0.20</code>, etc.) - Add <code>dns-nameservers</code> line explicitly</p>"},{"location":"virtualization/","title":"Proxmox VE Cluster Setup \u2013 Vesta Lab","text":"<p>This document describes how the Proxmox VE cluster is deployed in the Vesta Lab.</p>"},{"location":"virtualization/#cluster-nodes","title":"Cluster Nodes","text":"Node Hostname IP Role ve1 proxmox-ve1 10.10.0.2 Primary node ve2 proxmox-ve2 10.10.0.3 Secondary"},{"location":"virtualization/#network","title":"Network","text":"<ul> <li>VLAN 10 \u2013 Management: 10.10.0.0/24</li> <li>Bridge: <code>vmbr0</code>, with VLAN tag awareness</li> <li>Gateway: <code>10.10.0.1</code> (MikroTik)</li> </ul>"},{"location":"virtualization/#cluster-creation-on-ve1","title":"Cluster Creation (on ve1)","text":"<pre><code>pvecm create vesta-lab\n</code></pre>"},{"location":"virtualization/#join-node-on-ve2","title":"Join Node (on ve2)","text":"<pre><code>pvecm add 10.10.0.2\n</code></pre> <p>SSH key exchange and cluster handshake will complete automatically.</p>"},{"location":"virtualization/#result","title":"Result","text":"<p>Cluster with 2 nodes is functional and accessible via shared web UI at either IP.</p>"},{"location":"virtualization/#proxmox-ve-storage-configuration","title":"Proxmox VE \u2013 Storage Configuration","text":"<p>This document outlines the storage setup for each node in the Proxmox VE cluster.</p>"},{"location":"virtualization/#node-ve1","title":"Node <code>ve1</code>","text":"<ul> <li>Local ZFS pool: <code>rpool-ve1</code></li> <li>Device: 500 GB SSD</li> <li>Use: VM images, ISO uploads</li> </ul>"},{"location":"virtualization/#node-ve2","title":"Node <code>ve2</code>","text":"<ul> <li>LVM-thin default</li> <li>No local ZFS (lower spec)</li> </ul>"},{"location":"virtualization/#shared-storage","title":"Shared Storage","text":"Name Type Backed by Use Case lab-backups NFS TrueNAS (10.30.0.3) Backup target for PBS"},{"location":"virtualization/#add-nfs-storage-ui-or-cli","title":"Add NFS Storage (UI or CLI)","text":"<pre><code>pvesh create /storage   -storage lab-backups   -type nfs   -server 10.30.0.3   -export /mnt/lab-pool/lab-backups\n</code></pre>"},{"location":"virtualization/#result_1","title":"Result","text":"<ul> <li>Local storage for high-speed I/O</li> <li>Shared backup space for all nodes</li> </ul>"},{"location":"virtualization/#high-availability-ha-notes-proxmox-ve","title":"High Availability (HA) Notes \u2013 Proxmox VE","text":"<p>HA is not yet fully enabled in the lab, but design considerations are in place.</p>"},{"location":"virtualization/#planned-design","title":"\ufe0f Planned Design","text":"<ul> <li>At least 3 nodes recommended</li> <li>External quorum device (QDevice) required</li> <li>Shared storage (PBS via TrueNAS) partially supports migration</li> </ul>"},{"location":"virtualization/#current-limitations","title":"Current Limitations","text":"<ul> <li>2-node cluster = no HA fencing</li> <li>No QDevice yet</li> <li>ZFS local-only = manual migration</li> </ul>"},{"location":"virtualization/#live-migration","title":"Live Migration","text":"<p>Available between <code>ve1</code> and <code>ve2</code> when using shared storage or manually handled disks.</p>"},{"location":"virtualization/#next-steps","title":"Next Steps","text":"<ul> <li>Add QDevice or third test node</li> <li>Enable HA groups via UI</li> <li>Test failover behavior in real scenarios</li> </ul>"}]}